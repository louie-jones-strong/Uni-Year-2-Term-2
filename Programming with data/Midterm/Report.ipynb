{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mid term Report title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import yfinance as yf\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scope Limits\n",
    "StartTime = \"2012-05-01\"\n",
    "EndTime = \"2022-05-01\"\n",
    "TweetLimit = 100\n",
    "\n",
    "TweetCacheFolder = \"CachedTweets\"\n",
    "StockCacheFolder = \"CachedStockData\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what users do we care about\n",
    "\n",
    "# names from\n",
    "# https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts\n",
    "\n",
    "with open(\"TwitterUserNames.json\", \"r\") as file:\n",
    "\tusernames = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tweets from users\n",
    "def GetTweetsFromUser(username):\n",
    "\n",
    "\tif not os.path.isdir(TweetCacheFolder):\n",
    "\t\tos.mkdir(TweetCacheFolder)\n",
    "\n",
    "\tcachePath = os.path.join(TweetCacheFolder, \"tweets_\" + username + \".csv\")\n",
    "\n",
    "\t# cache exists\n",
    "\tif os.path.exists(cachePath):\n",
    "\t\tdf = pd.read_csv(cachePath)\n",
    "\n",
    "\telse:\n",
    "\t\tquery = \"(from:\" + username + \") since:\" + StartTime + \" until:\" + EndTime\n",
    "\t\t\n",
    "\t\ttweets = []\n",
    "\t\tfor tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "\n",
    "\t\t\tif len(tweets) == TweetLimit:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\t# print(tweet.json())\n",
    "\t\t\t\t#break\n",
    "\t\t\t\ttweets.append([tweet.date, tweet.user.username, tweet.content, tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount, tweet.id])\n",
    "\t\t\n",
    "\t\tdf = pd.DataFrame(tweets, columns=['Date', 'User', 'Content', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'TweetID'])\n",
    "\n",
    "\t\t# to save to csv as a cache\n",
    "\t\tdf.to_csv(cachePath)\n",
    "\t\n",
    "\n",
    "\treturn df\n",
    "\n",
    "tweetsDf = GetTweetsFromUser(usernames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for username in usernames:\n",
    "\ttweetsDf = GetTweetsFromUser(username)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stocks to track\n",
    "with open(\"StockTags_SnP.json\", \"r\") as file:\n",
    "\tstockTags = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadStockData(stockTag):\n",
    "\n",
    "\tif not os.path.isdir(StockCacheFolder):\n",
    "\t\tos.mkdir(StockCacheFolder)\n",
    "\n",
    "\tcachePath = os.path.join(StockCacheFolder, \"Stock_\" + stockTag + \".csv\")\n",
    "\n",
    "\t# cache exists\n",
    "\tif os.path.exists(cachePath):\n",
    "\t\tdf = pd.read_csv(cachePath)\n",
    "\n",
    "\tif not os.path.exists(cachePath):\n",
    "\t\tstock = yf.Ticker(stockTag)\n",
    "\n",
    "\t\thistData = stock.history(start=StartTime, end=EndTime, interval=\"1d\")\n",
    "\n",
    "\t\t#save data to local cache file\n",
    "\t\thistData.to_csv(cachePath, index=False)\n",
    "\telse:\n",
    "\n",
    "\t\thistData = pd.read_csv(cachePath)\n",
    "\n",
    "\treturn histData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ALXN: No data found, symbol may be delisted\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- COG: No data found, symbol may be delisted\n",
      "- FLIR: No data found, symbol may be delisted\n",
      "- HFC: No data found, symbol may be delisted\n",
      "- INFO: No data found, symbol may be delisted\n",
      "- KSU: No data found, symbol may be delisted\n",
      "- LB: No data found, symbol may be delisted\n",
      "- MXIM: No data found, symbol may be delisted\n",
      "- NKE1964: No data found, symbol may be delisted\n",
      "- TPR2017: No data found, symbol may be delisted\n",
      "- VAR: No data found, symbol may be delisted\n",
      "- VIAC: No data found, symbol may be delisted\n",
      "- WLTW: No data found, symbol may be delisted\n",
      "- XLNX: No data found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for stockTag in stockTags:\n",
    "\tLoadStockData(stockTag)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e03891b53087abc58e95159b2c70e6ab6b812f7c74a522802c5c9765390d0ed"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
